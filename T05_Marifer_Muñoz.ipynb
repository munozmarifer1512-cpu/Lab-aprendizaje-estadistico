{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250a2198-4b1e-41ab-94a6-cc705f019249",
   "metadata": {},
   "source": [
    "# T05 Motor trend Car Road Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d93a3a-2789-4f59-88dc-ecf86d087842",
   "metadata": {},
   "source": [
    "|                |   |\n",
    ":----------------|---|\n",
    "| **Nombre**     |Maria Fernanda Muñoz Sevilla   |\n",
    "| **Fecha**      |15/09/25   |\n",
    "| **Expediente** |751190   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499154d-5db9-4ebd-a5b5-8a5c0d9a48f6",
   "metadata": {},
   "source": [
    "Utiliza el archivo \"Motor Trend Car Road Tests.xlsx\" y completa las siguientes actividades:\n",
    "\n",
    "## 1.1 Realiza una regresión tomando 'mpg' como salida y eliminando la columna 'model'. Considera todos los demás factores como numéricos/ordinales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf5f864-8b30-467c-b7d1-dad3cc9c5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132a2f66-3e12-4ee6-8f02-a27b10ad6736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"C:/Users/munoz/Downloads/lab_apre_est/Motor Trend Car Road Tests.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69205ad5-52de-4355-b1dc-51325678881f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=df.drop(columns=[\"model\"])\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e7f6e-785b-4f36-aa3b-bebcbc6c19ec",
   "metadata": {},
   "source": [
    "- Calcula el R2 e interpreta los signos de los betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1041b50-c121-4049-8dc9-f4684ee4838c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>3.79e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:25</td>     <th>  Log-Likelihood:    </th> <td> -69.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   161.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   177.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   12.3034</td> <td>   18.718</td> <td>    0.657</td> <td> 0.518</td> <td>  -26.623</td> <td>   51.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1114</td> <td>    1.045</td> <td>   -0.107</td> <td> 0.916</td> <td>   -2.285</td> <td>    2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0133</td> <td>    0.018</td> <td>    0.747</td> <td> 0.463</td> <td>   -0.024</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0215</td> <td>    0.022</td> <td>   -0.987</td> <td> 0.335</td> <td>   -0.067</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.7871</td> <td>    1.635</td> <td>    0.481</td> <td> 0.635</td> <td>   -2.614</td> <td>    4.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -3.7153</td> <td>    1.894</td> <td>   -1.961</td> <td> 0.063</td> <td>   -7.655</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.8210</td> <td>    0.731</td> <td>    1.123</td> <td> 0.274</td> <td>   -0.699</td> <td>    2.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.3178</td> <td>    2.105</td> <td>    0.151</td> <td> 0.881</td> <td>   -4.059</td> <td>    4.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    2.5202</td> <td>    2.057</td> <td>    1.225</td> <td> 0.234</td> <td>   -1.757</td> <td>    6.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.6554</td> <td>    1.493</td> <td>    0.439</td> <td> 0.665</td> <td>   -2.450</td> <td>    3.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1994</td> <td>    0.829</td> <td>   -0.241</td> <td> 0.812</td> <td>   -1.923</td> <td>    1.524</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.907</td> <th>  Durbin-Watson:     </th> <td>   1.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.385</td> <th>  Jarque-Bera (JB):  </th> <td>   1.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.521</td> <th>  Prob(JB):          </th> <td>   0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.526</td> <th>  Cond. No.          </th> <td>1.22e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.22e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.869   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.807   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     13.93   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &  3.79e-07   \\\\\n",
       "\\textbf{Time:}             &     07:11:25     & \\textbf{  Log-Likelihood:    } &   -69.855   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     161.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          21      & \\textbf{  BIC:               } &     177.8   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      12.3034  &       18.718     &     0.657  &         0.518        &      -26.623    &       51.229     \\\\\n",
       "\\textbf{x1}    &      -0.1114  &        1.045     &    -0.107  &         0.916        &       -2.285    &        2.062     \\\\\n",
       "\\textbf{x2}    &       0.0133  &        0.018     &     0.747  &         0.463        &       -0.024    &        0.050     \\\\\n",
       "\\textbf{x3}    &      -0.0215  &        0.022     &    -0.987  &         0.335        &       -0.067    &        0.024     \\\\\n",
       "\\textbf{x4}    &       0.7871  &        1.635     &     0.481  &         0.635        &       -2.614    &        4.188     \\\\\n",
       "\\textbf{x5}    &      -3.7153  &        1.894     &    -1.961  &         0.063        &       -7.655    &        0.224     \\\\\n",
       "\\textbf{x6}    &       0.8210  &        0.731     &     1.123  &         0.274        &       -0.699    &        2.341     \\\\\n",
       "\\textbf{x7}    &       0.3178  &        2.105     &     0.151  &         0.881        &       -4.059    &        4.694     \\\\\n",
       "\\textbf{x8}    &       2.5202  &        2.057     &     1.225  &         0.234        &       -1.757    &        6.797     \\\\\n",
       "\\textbf{x9}    &       0.6554  &        1.493     &     0.439  &         0.665        &       -2.450    &        3.761     \\\\\n",
       "\\textbf{x10}   &      -0.1994  &        0.829     &    -0.241  &         0.812        &       -1.923    &        1.524     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.907 & \\textbf{  Durbin-Watson:     } &    1.861  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.385 & \\textbf{  Jarque-Bera (JB):  } &    1.747  \\\\\n",
       "\\textbf{Skew:}          &  0.521 & \\textbf{  Prob(JB):          } &    0.418  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.526 & \\textbf{  Cond. No.          } & 1.22e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.22e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.869\n",
       "Model:                            OLS   Adj. R-squared:                  0.807\n",
       "Method:                 Least Squares   F-statistic:                     13.93\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):           3.79e-07\n",
       "Time:                        07:11:25   Log-Likelihood:                -69.855\n",
       "No. Observations:                  32   AIC:                             161.7\n",
       "Df Residuals:                      21   BIC:                             177.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         12.3034     18.718      0.657      0.518     -26.623      51.229\n",
       "x1            -0.1114      1.045     -0.107      0.916      -2.285       2.062\n",
       "x2             0.0133      0.018      0.747      0.463      -0.024       0.050\n",
       "x3            -0.0215      0.022     -0.987      0.335      -0.067       0.024\n",
       "x4             0.7871      1.635      0.481      0.635      -2.614       4.188\n",
       "x5            -3.7153      1.894     -1.961      0.063      -7.655       0.224\n",
       "x6             0.8210      0.731      1.123      0.274      -0.699       2.341\n",
       "x7             0.3178      2.105      0.151      0.881      -4.059       4.694\n",
       "x8             2.5202      2.057      1.225      0.234      -1.757       6.797\n",
       "x9             0.6554      1.493      0.439      0.665      -2.450       3.761\n",
       "x10           -0.1994      0.829     -0.241      0.812      -1.923       1.524\n",
       "==============================================================================\n",
       "Omnibus:                        1.907   Durbin-Watson:                   1.861\n",
       "Prob(Omnibus):                  0.385   Jarque-Bera (JB):                1.747\n",
       "Skew:                           0.521   Prob(JB):                        0.418\n",
       "Kurtosis:                       2.526   Cond. No.                     1.22e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.22e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dat.iloc[:,1:].values\n",
    "y=dat.mpg\n",
    "n=len(y)\n",
    "unos=np.ones([n,1])\n",
    "X=np.hstack([unos,x])\n",
    "ols=sm.OLS(y,X)\n",
    "resultados=ols.fit()\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd122e0-2926-4f18-a945-4067e616e12d",
   "metadata": {},
   "source": [
    "En esta regresión lineal sin escalar ni entrenar, podemos observar que tenemos betas tanto por debajo de cero, como muy por encima. Los betas que se encuentran por encima de cero, nos hablan de una relación donde incrementa nuestra variable y, mientras que, las betas menores a 0 representan la disminución en y. Además, nuestra r2 nos dice que de nuestro modelo se puede explicar el 86.9%, mientra que el resto queda en el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9d72a-0e90-4e20-8972-61270a284c6c",
   "metadata": {},
   "source": [
    "\n",
    "- Realiza un train-test-split donde se use el 40% de los datos para entrenar. Calcula el R2 de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1810015b-3f57-46e5-a7ac-4a1ce94b83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos los datos\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.4, random_state=137)\n",
    "\n",
    "#estandarizamos\n",
    "scaler=StandardScaler().fit(x_train1)\n",
    "\n",
    "x_train_scaled1=scaler.transform(x_train1)\n",
    "x_test_scaled1=scaler.transform(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829fa974-d530-4d1a-81e3-df56ed5c0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munoz\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=19\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th>  <td>0.0101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:27</td>     <th>  Log-Likelihood:    </th> <td> -40.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    19</td>      <th>  AIC:               </th> <td>   103.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   113.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   18.4947</td> <td>    0.729</td> <td>   25.366</td> <td> 0.000</td> <td>   16.813</td> <td>   20.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.182e-15</td> <td> 1.98e-15</td> <td>    0.598</td> <td> 0.566</td> <td>-3.37e-15</td> <td> 5.74e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -2.8779</td> <td>    3.427</td> <td>   -0.840</td> <td> 0.425</td> <td>  -10.781</td> <td>    5.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.9201</td> <td>    3.625</td> <td>   -0.254</td> <td> 0.806</td> <td>   -9.280</td> <td>    7.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1825</td> <td>    2.839</td> <td>    0.064</td> <td> 0.950</td> <td>   -6.363</td> <td>    6.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.2609</td> <td>    1.492</td> <td>    0.175</td> <td> 0.865</td> <td>   -3.179</td> <td>    3.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -2.1215</td> <td>    3.207</td> <td>   -0.662</td> <td> 0.527</td> <td>   -9.517</td> <td>    5.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.1404</td> <td>    1.998</td> <td>    0.070</td> <td> 0.946</td> <td>   -4.468</td> <td>    4.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.6393</td> <td>    2.275</td> <td>   -0.281</td> <td> 0.786</td> <td>   -5.884</td> <td>    4.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.3812</td> <td>    1.705</td> <td>    0.224</td> <td> 0.829</td> <td>   -3.550</td> <td>    4.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1370</td> <td>    2.167</td> <td>   -0.063</td> <td> 0.951</td> <td>   -5.134</td> <td>    4.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.6824</td> <td>    2.324</td> <td>   -0.294</td> <td> 0.776</td> <td>   -6.041</td> <td>    4.676</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.180</td> <th>  Durbin-Watson:     </th> <td>   1.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.204</td> <th>  Jarque-Bera (JB):  </th> <td>   1.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.480</td> <th>  Prob(JB):          </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.867</td> <th>  Cond. No.          </th> <td>3.21e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.02e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.879   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.727   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5.802   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &   0.0101    \\\\\n",
       "\\textbf{Time:}             &     07:11:27     & \\textbf{  Log-Likelihood:    } &   -40.712   \\\\\n",
       "\\textbf{No. Observations:} &          19      & \\textbf{  AIC:               } &     103.4   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     113.8   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      18.4947  &        0.729     &    25.366  &         0.000        &       16.813    &       20.176     \\\\\n",
       "\\textbf{x1}    &    1.182e-15  &     1.98e-15     &     0.598  &         0.566        &    -3.37e-15    &     5.74e-15     \\\\\n",
       "\\textbf{x2}    &      -2.8779  &        3.427     &    -0.840  &         0.425        &      -10.781    &        5.025     \\\\\n",
       "\\textbf{x3}    &      -0.9201  &        3.625     &    -0.254  &         0.806        &       -9.280    &        7.440     \\\\\n",
       "\\textbf{x4}    &       0.1825  &        2.839     &     0.064  &         0.950        &       -6.363    &        6.728     \\\\\n",
       "\\textbf{x5}    &       0.2609  &        1.492     &     0.175  &         0.865        &       -3.179    &        3.701     \\\\\n",
       "\\textbf{x6}    &      -2.1215  &        3.207     &    -0.662  &         0.527        &       -9.517    &        5.274     \\\\\n",
       "\\textbf{x7}    &       0.1404  &        1.998     &     0.070  &         0.946        &       -4.468    &        4.749     \\\\\n",
       "\\textbf{x8}    &      -0.6393  &        2.275     &    -0.281  &         0.786        &       -5.884    &        4.606     \\\\\n",
       "\\textbf{x9}    &       0.3812  &        1.705     &     0.224  &         0.829        &       -3.550    &        4.312     \\\\\n",
       "\\textbf{x10}   &      -0.1370  &        2.167     &    -0.063  &         0.951        &       -5.134    &        4.860     \\\\\n",
       "\\textbf{x11}   &      -0.6824  &        2.324     &    -0.294  &         0.776        &       -6.041    &        4.676     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.180 & \\textbf{  Durbin-Watson:     } &    1.104  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.204 & \\textbf{  Jarque-Bera (JB):  } &    1.324  \\\\\n",
       "\\textbf{Skew:}          &  0.480 & \\textbf{  Prob(JB):          } &    0.516  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.867 & \\textbf{  Cond. No.          } & 3.21e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.02e-31. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.879\n",
       "Model:                            OLS   Adj. R-squared:                  0.727\n",
       "Method:                 Least Squares   F-statistic:                     5.802\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):             0.0101\n",
       "Time:                        07:11:27   Log-Likelihood:                -40.712\n",
       "No. Observations:                  19   AIC:                             103.4\n",
       "Df Residuals:                       8   BIC:                             113.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         18.4947      0.729     25.366      0.000      16.813      20.176\n",
       "x1          1.182e-15   1.98e-15      0.598      0.566   -3.37e-15    5.74e-15\n",
       "x2            -2.8779      3.427     -0.840      0.425     -10.781       5.025\n",
       "x3            -0.9201      3.625     -0.254      0.806      -9.280       7.440\n",
       "x4             0.1825      2.839      0.064      0.950      -6.363       6.728\n",
       "x5             0.2609      1.492      0.175      0.865      -3.179       3.701\n",
       "x6            -2.1215      3.207     -0.662      0.527      -9.517       5.274\n",
       "x7             0.1404      1.998      0.070      0.946      -4.468       4.749\n",
       "x8            -0.6393      2.275     -0.281      0.786      -5.884       4.606\n",
       "x9             0.3812      1.705      0.224      0.829      -3.550       4.312\n",
       "x10           -0.1370      2.167     -0.063      0.951      -5.134       4.860\n",
       "x11           -0.6824      2.324     -0.294      0.776      -6.041       4.676\n",
       "==============================================================================\n",
       "Omnibus:                        3.180   Durbin-Watson:                   1.104\n",
       "Prob(Omnibus):                  0.204   Jarque-Bera (JB):                1.324\n",
       "Skew:                           0.480   Prob(JB):                        0.516\n",
       "Kurtosis:                       3.867   Cond. No.                     3.21e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.02e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos la regresión lineal\n",
    "x_train_e= sm.add_constant(x_train_scaled1)\n",
    "resultado= sm.OLS(y_train1,x_train_e).fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b4694-dc4b-41c7-893d-521de95ae268",
   "metadata": {},
   "source": [
    "Ahora que escalamos podemos ver que incrementaron nuestras betas negativas, dandonos a entender que en este modelo la mayoria de nuestras variables hacen que disminuya nuestra variable y (\"mpg\"). También, observamos que nuestro r2 es de 0.879, por lo que, el 87.9% es explicado por el modelo, el resto queda del error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f12126-32a7-4427-adc8-a6e8d4306156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8788249154881685\n",
      "R2 de test:  0.6781478185882241\n"
     ]
    }
   ],
   "source": [
    "#Sacamos lor R2 de x_train y x_test\n",
    "\n",
    "#preparamos x_test\n",
    "x_test_e=sm.add_constant(x_test_scaled1)\n",
    "y_pred1=resultado.predict(x_test_e)\n",
    "#calculamos r2 de xtrain\n",
    "r2_train=resultado.rsquared\n",
    "print(\"R2 de train: \",r2_train)\n",
    "\n",
    "#calculamos r2 de xtest\n",
    "r2_test=r2_score(y_test1, y_pred1)\n",
    "print(\"R2 de test: \",r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85fbc1-eadc-4604-a645-f2c280ba4be9",
   "metadata": {},
   "source": [
    "- Añade regularización L2 con un hiperparámetro lambda decidido por ti. Cambia este valor y compara con varios distintos los R2 de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3acf330-20da-4699-9ced-32abd21eeda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8773082539790075\n",
      "R2 de test:  0.7170867292018437\n"
     ]
    }
   ],
   "source": [
    "#Con alfa = 0.5, con xtrain_scaled y xtest_scaled\n",
    "ridge1= Ridge(alpha=0.5)\n",
    "ridge1.fit(x_train_scaled1, y_train1)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train1=ridge1.predict(x_train_scaled1)\n",
    "y_pred_test1=ridge1.predict(x_test_scaled1)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train1=r2_score(y_train1,y_pred_train1)\n",
    "r2_ridge_test1=r2_score(y_test1,y_pred_test1)\n",
    "print(\"R2 de train: \", r2_ridge_train1)\n",
    "print(\"R2 de test: \", r2_ridge_test1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1acb595a-8ca0-4058-bc35-d08d3c57b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8757139730165581\n",
      "R2 de test:  0.7282860802849515\n"
     ]
    }
   ],
   "source": [
    "#Con alfa=1\n",
    "ridge2= Ridge(alpha=1)\n",
    "ridge2.fit(x_train_scaled1, y_train1)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train2=ridge2.predict(x_train_scaled1)\n",
    "y_pred_test2=ridge2.predict(x_test_scaled1)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train2=r2_score(y_train1,y_pred_train2)\n",
    "r2_ridge_test2=r2_score(y_test1,y_pred_test2)\n",
    "print(\"R2 de train: \", r2_ridge_train2)\n",
    "print(\"R2 de test: \", r2_ridge_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6d90164-e560-4811-865a-9243a7ef752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8601362367025545\n",
      "R2 de test:  0.7431630893996333\n"
     ]
    }
   ],
   "source": [
    "# Con alfa=10\n",
    "ridge3= Ridge(alpha=10)\n",
    "ridge3.fit(x_train_scaled1, y_train1)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train3=ridge3.predict(x_train_scaled1)\n",
    "y_pred_test3=ridge3.predict(x_test_scaled1)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train3=r2_score(y_train1,y_pred_train3)\n",
    "r2_ridge_test3=r2_score(y_test1,y_pred_test3)\n",
    "print(\"R2 de train: \", r2_ridge_train3)\n",
    "print(\"R2 de test: \", r2_ridge_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72c322-6b7c-4730-9bf0-80c3e4d6385b",
   "metadata": {},
   "source": [
    "Vinedo los resultados, considero que el mejor ajuste fue el de lambda = 10, ya que, muestra una mayor generalización de los datos. Mientras que, para lambda = 1, es un mejor balance, y el lambda = 0.5, es muy parecido al modelo sin penalizar, ya que el ajuste es muy pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91251992-1dba-44d6-acc8-2844ff287252",
   "metadata": {},
   "source": [
    "## 1.2 Repite el ejercicio anterior usando 'qsec' como salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df8a43-0259-4cfe-a199-59034601c233",
   "metadata": {},
   "source": [
    "- Calcula el R2 e interpreta los signos de los betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4919c662-0ea2-4ef1-b1e8-59d22d1bc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>qsec</td>       <th>  R-squared:         </th> <td>   0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>2.44e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:36</td>     <th>  Log-Likelihood:    </th> <td> -30.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   82.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   98.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   17.7762</td> <td>    3.876</td> <td>    4.586</td> <td> 0.000</td> <td>    9.716</td> <td>   25.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0690</td> <td>    0.061</td> <td>    1.123</td> <td> 0.274</td> <td>   -0.059</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.3627</td> <td>    0.293</td> <td>   -1.239</td> <td> 0.229</td> <td>   -0.971</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0075</td> <td>    0.005</td> <td>   -1.505</td> <td> 0.147</td> <td>   -0.018</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0016</td> <td>    0.006</td> <td>   -0.242</td> <td> 0.811</td> <td>   -0.015</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1311</td> <td>    0.476</td> <td>   -0.275</td> <td> 0.786</td> <td>   -1.121</td> <td>    0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    1.4963</td> <td>    0.500</td> <td>    2.990</td> <td> 0.007</td> <td>    0.456</td> <td>    2.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.9700</td> <td>    0.573</td> <td>    1.694</td> <td> 0.105</td> <td>   -0.221</td> <td>    2.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.9012</td> <td>    0.585</td> <td>   -1.540</td> <td> 0.139</td> <td>   -2.118</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.2013</td> <td>    0.433</td> <td>   -0.465</td> <td> 0.647</td> <td>   -1.101</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.2736</td> <td>    0.233</td> <td>   -1.174</td> <td> 0.254</td> <td>   -0.758</td> <td>    0.211</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>21.069</td> <th>  Durbin-Watson:     </th> <td>   2.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.470</td> <th>  Prob(JB):          </th> <td>4.84e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.481</td> <th>  Cond. No.          </th> <td>8.77e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       qsec       & \\textbf{  R-squared:         } &     0.875   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.815   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     14.66   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &  2.44e-07   \\\\\n",
       "\\textbf{Time:}             &     07:11:36     & \\textbf{  Log-Likelihood:    } &   -30.242   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     82.48   \\\\\n",
       "\\textbf{Df Residuals:}     &          21      & \\textbf{  BIC:               } &     98.61   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      17.7762  &        3.876     &     4.586  &         0.000        &        9.716    &       25.837     \\\\\n",
       "\\textbf{x1}    &       0.0690  &        0.061     &     1.123  &         0.274        &       -0.059    &        0.197     \\\\\n",
       "\\textbf{x2}    &      -0.3627  &        0.293     &    -1.239  &         0.229        &       -0.971    &        0.246     \\\\\n",
       "\\textbf{x3}    &      -0.0075  &        0.005     &    -1.505  &         0.147        &       -0.018    &        0.003     \\\\\n",
       "\\textbf{x4}    &      -0.0016  &        0.006     &    -0.242  &         0.811        &       -0.015    &        0.012     \\\\\n",
       "\\textbf{x5}    &      -0.1311  &        0.476     &    -0.275  &         0.786        &       -1.121    &        0.859     \\\\\n",
       "\\textbf{x6}    &       1.4963  &        0.500     &     2.990  &         0.007        &        0.456    &        2.537     \\\\\n",
       "\\textbf{x7}    &       0.9700  &        0.573     &     1.694  &         0.105        &       -0.221    &        2.161     \\\\\n",
       "\\textbf{x8}    &      -0.9012  &        0.585     &    -1.540  &         0.139        &       -2.118    &        0.316     \\\\\n",
       "\\textbf{x9}    &      -0.2013  &        0.433     &    -0.465  &         0.647        &       -1.101    &        0.699     \\\\\n",
       "\\textbf{x10}   &      -0.2736  &        0.233     &    -1.174  &         0.254        &       -0.758    &        0.211     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 21.069 & \\textbf{  Durbin-Watson:     } &    2.573  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   38.291  \\\\\n",
       "\\textbf{Skew:}          &  1.470 & \\textbf{  Prob(JB):          } & 4.84e-09  \\\\\n",
       "\\textbf{Kurtosis:}      &  7.481 & \\textbf{  Cond. No.          } & 8.77e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 8.77e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   qsec   R-squared:                       0.875\n",
       "Model:                            OLS   Adj. R-squared:                  0.815\n",
       "Method:                 Least Squares   F-statistic:                     14.66\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):           2.44e-07\n",
       "Time:                        07:11:36   Log-Likelihood:                -30.242\n",
       "No. Observations:                  32   AIC:                             82.48\n",
       "Df Residuals:                      21   BIC:                             98.61\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         17.7762      3.876      4.586      0.000       9.716      25.837\n",
       "x1             0.0690      0.061      1.123      0.274      -0.059       0.197\n",
       "x2            -0.3627      0.293     -1.239      0.229      -0.971       0.246\n",
       "x3            -0.0075      0.005     -1.505      0.147      -0.018       0.003\n",
       "x4            -0.0016      0.006     -0.242      0.811      -0.015       0.012\n",
       "x5            -0.1311      0.476     -0.275      0.786      -1.121       0.859\n",
       "x6             1.4963      0.500      2.990      0.007       0.456       2.537\n",
       "x7             0.9700      0.573      1.694      0.105      -0.221       2.161\n",
       "x8            -0.9012      0.585     -1.540      0.139      -2.118       0.316\n",
       "x9            -0.2013      0.433     -0.465      0.647      -1.101       0.699\n",
       "x10           -0.2736      0.233     -1.174      0.254      -0.758       0.211\n",
       "==============================================================================\n",
       "Omnibus:                       21.069   Durbin-Watson:                   2.573\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.291\n",
       "Skew:                           1.470   Prob(JB):                     4.84e-09\n",
       "Kurtosis:                       7.481   Cond. No.                     8.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_12=dat.drop(columns=[\"qsec\"]).values.reshape(-1,10)\n",
    "y_12=dat.qsec\n",
    "n=len(y_12)\n",
    "unos=np.ones([n,1])\n",
    "X_12=np.hstack([unos,x_12])\n",
    "ols=sm.OLS(y_12,X_12)\n",
    "resultados=ols.fit()\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f755bf-f0c0-4240-a3db-b654f9edd809",
   "metadata": {},
   "source": [
    "Podmeos observar que el modelo presenta más variables que disminuyen nuestra variable y (\"qsec\"), además, el modelo puede explicar el 87.5%, muy parecido al modelo anterior con y=mpg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284617ae-0549-4eaa-a8d2-75425810ee08",
   "metadata": {},
   "source": [
    "- Realiza un train-test-split donde se use el 40% de los datos para entrenar. Calcula el R2 de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbeb8f96-809a-4f48-a4fe-1b50443277c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos los datos\n",
    "x_train12, x_test12, y_train12, y_test12 = train_test_split(X_12, y_12, test_size=0.4, random_state=137)\n",
    "\n",
    "#estandarizamos\n",
    "scaler=StandardScaler().fit(x_train12)\n",
    "\n",
    "x_train_scaled12=scaler.transform(x_train12)\n",
    "x_test_scaled12=scaler.transform(x_test12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7289fe62-5c28-4886-8fcb-5920ef3ff928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munoz\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=19\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>qsec</td>       <th>  R-squared:         </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th>  <td>0.0140</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:38</td>     <th>  Log-Likelihood:    </th> <td> -20.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    19</td>      <th>  AIC:               </th> <td>   62.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th> <td>   72.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   17.8511</td> <td>    0.247</td> <td>   72.185</td> <td> 0.000</td> <td>   17.281</td> <td>   18.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 4.826e-16</td> <td> 8.01e-16</td> <td>    0.603</td> <td> 0.563</td> <td>-1.36e-15</td> <td> 2.33e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0499</td> <td>    0.710</td> <td>    0.070</td> <td> 0.946</td> <td>   -1.588</td> <td>    1.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -1.5136</td> <td>    1.088</td> <td>   -1.391</td> <td> 0.202</td> <td>   -4.023</td> <td>    0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.3262</td> <td>    1.142</td> <td>   -1.161</td> <td> 0.279</td> <td>   -3.960</td> <td>    1.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.5221</td> <td>    0.945</td> <td>    0.552</td> <td> 0.596</td> <td>   -1.657</td> <td>    2.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0714</td> <td>    0.506</td> <td>    0.141</td> <td> 0.891</td> <td>   -1.096</td> <td>    1.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    1.5030</td> <td>    0.983</td> <td>    1.530</td> <td> 0.165</td> <td>   -0.763</td> <td>    3.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1762</td> <td>    0.773</td> <td>   -0.228</td> <td> 0.825</td> <td>   -1.958</td> <td>    1.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.6846</td> <td>    0.527</td> <td>   -1.299</td> <td> 0.230</td> <td>   -1.900</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1163</td> <td>    0.734</td> <td>   -0.158</td> <td> 0.878</td> <td>   -1.809</td> <td>    1.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.7713</td> <td>    0.744</td> <td>   -1.037</td> <td> 0.330</td> <td>   -2.487</td> <td>    0.944</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.980</td> <th>  Durbin-Watson:     </th> <td>   2.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.613</td> <th>  Jarque-Bera (JB):  </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.453</td> <th>  Prob(JB):          </th> <td>   0.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.634</td> <th>  Cond. No.          </th> <td>1.07e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.02e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       qsec       & \\textbf{  R-squared:         } &     0.867   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.701   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5.214   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &   0.0140    \\\\\n",
       "\\textbf{Time:}             &     07:11:38     & \\textbf{  Log-Likelihood:    } &   -20.168   \\\\\n",
       "\\textbf{No. Observations:} &          19      & \\textbf{  AIC:               } &     62.34   \\\\\n",
       "\\textbf{Df Residuals:}     &           8      & \\textbf{  BIC:               } &     72.73   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      17.8511  &        0.247     &    72.185  &         0.000        &       17.281    &       18.421     \\\\\n",
       "\\textbf{x1}    &    4.826e-16  &     8.01e-16     &     0.603  &         0.563        &    -1.36e-15    &     2.33e-15     \\\\\n",
       "\\textbf{x2}    &       0.0499  &        0.710     &     0.070  &         0.946        &       -1.588    &        1.688     \\\\\n",
       "\\textbf{x3}    &      -1.5136  &        1.088     &    -1.391  &         0.202        &       -4.023    &        0.995     \\\\\n",
       "\\textbf{x4}    &      -1.3262  &        1.142     &    -1.161  &         0.279        &       -3.960    &        1.307     \\\\\n",
       "\\textbf{x5}    &       0.5221  &        0.945     &     0.552  &         0.596        &       -1.657    &        2.702     \\\\\n",
       "\\textbf{x6}    &       0.0714  &        0.506     &     0.141  &         0.891        &       -1.096    &        1.239     \\\\\n",
       "\\textbf{x7}    &       1.5030  &        0.983     &     1.530  &         0.165        &       -0.763    &        3.769     \\\\\n",
       "\\textbf{x8}    &      -0.1762  &        0.773     &    -0.228  &         0.825        &       -1.958    &        1.606     \\\\\n",
       "\\textbf{x9}    &      -0.6846  &        0.527     &    -1.299  &         0.230        &       -1.900    &        0.531     \\\\\n",
       "\\textbf{x10}   &      -0.1163  &        0.734     &    -0.158  &         0.878        &       -1.809    &        1.576     \\\\\n",
       "\\textbf{x11}   &      -0.7713  &        0.744     &    -1.037  &         0.330        &       -2.487    &        0.944     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.980 & \\textbf{  Durbin-Watson:     } &    2.087  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.613 & \\textbf{  Jarque-Bera (JB):  } &    0.756  \\\\\n",
       "\\textbf{Skew:}          &  0.453 & \\textbf{  Prob(JB):          } &    0.685  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.634 & \\textbf{  Cond. No.          } & 1.07e+17  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.02e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   qsec   R-squared:                       0.867\n",
       "Model:                            OLS   Adj. R-squared:                  0.701\n",
       "Method:                 Least Squares   F-statistic:                     5.214\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):             0.0140\n",
       "Time:                        07:11:38   Log-Likelihood:                -20.168\n",
       "No. Observations:                  19   AIC:                             62.34\n",
       "Df Residuals:                       8   BIC:                             72.73\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         17.8511      0.247     72.185      0.000      17.281      18.421\n",
       "x1          4.826e-16   8.01e-16      0.603      0.563   -1.36e-15    2.33e-15\n",
       "x2             0.0499      0.710      0.070      0.946      -1.588       1.688\n",
       "x3            -1.5136      1.088     -1.391      0.202      -4.023       0.995\n",
       "x4            -1.3262      1.142     -1.161      0.279      -3.960       1.307\n",
       "x5             0.5221      0.945      0.552      0.596      -1.657       2.702\n",
       "x6             0.0714      0.506      0.141      0.891      -1.096       1.239\n",
       "x7             1.5030      0.983      1.530      0.165      -0.763       3.769\n",
       "x8            -0.1762      0.773     -0.228      0.825      -1.958       1.606\n",
       "x9            -0.6846      0.527     -1.299      0.230      -1.900       0.531\n",
       "x10           -0.1163      0.734     -0.158      0.878      -1.809       1.576\n",
       "x11           -0.7713      0.744     -1.037      0.330      -2.487       0.944\n",
       "==============================================================================\n",
       "Omnibus:                        0.980   Durbin-Watson:                   2.087\n",
       "Prob(Omnibus):                  0.613   Jarque-Bera (JB):                0.756\n",
       "Skew:                           0.453   Prob(JB):                        0.685\n",
       "Kurtosis:                       2.634   Cond. No.                     1.07e+17\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.02e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos la regresión lineal\n",
    "x_train_e12= sm.add_constant(x_train_scaled12)\n",
    "resultado= sm.OLS(y_train12,x_train_e12).fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afca7f-48e7-4f92-bfbe-b01bd93eebbd",
   "metadata": {},
   "source": [
    "AL escalar, entrenar y sacar la prueba podemos ver que el r2 dismunuyo a 0.867, esto porque tenemos un mejor ajuste de los datos. De igual forma, la mayoría de las variables presentan una disminución con la relación de la variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa58e4f2-7f28-425e-9b57-373f162fad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8669774049790414\n",
      "R2 de test:  0.6814395697520064\n"
     ]
    }
   ],
   "source": [
    "#Sacamos lor R2 de x_train y x_test\n",
    "\n",
    "#preparamos x_test\n",
    "x_test_e12=sm.add_constant(x_test_scaled12)\n",
    "y_pred12=resultado.predict(x_test_e12)\n",
    "#calculamos r2 de xtrain\n",
    "r2_train12=resultado.rsquared\n",
    "print(\"R2 de train: \",r2_train12)\n",
    "\n",
    "#calculamos r2 de xtest\n",
    "r2_test12=r2_score(y_test12, y_pred12)\n",
    "print(\"R2 de test: \",r2_test12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83d35a-1410-4344-9654-fe053fd38c93",
   "metadata": {},
   "source": [
    "- Añade regularización L2 con un hiperparámetro lambda decidido por ti. Cambia este valor y compara con varios distintos los R2 de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffba94ea-995c-406f-92f0-e5bc663f6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8566464863628895\n",
      "R2 de test:  0.8054592665804765\n"
     ]
    }
   ],
   "source": [
    "#Con alfa = 0.5, con xtrain_scaled y xtest_scaled\n",
    "ridge12= Ridge(alpha=0.5)\n",
    "ridge12.fit(x_train_scaled12, y_train12)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train12=ridge12.predict(x_train_scaled12)\n",
    "y_pred_test12=ridge12.predict(x_test_scaled12)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train12=r2_score(y_train12,y_pred_train12)\n",
    "r2_ridge_test12=r2_score(y_test12,y_pred_test12)\n",
    "print(\"R2 de train: \", r2_ridge_train12)\n",
    "print(\"R2 de test: \", r2_ridge_test12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc445846-4e1f-404d-94d8-1fb392e8f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.8483218557627674\n",
      "R2 de test:  0.8227910634318731\n"
     ]
    }
   ],
   "source": [
    "#Con alfa = 1, con xtrain_scaled y xtest_scaled\n",
    "ridge12_2= Ridge(alpha=1)\n",
    "ridge12_2.fit(x_train_scaled12, y_train12)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train12_2=ridge12_2.predict(x_train_scaled12)\n",
    "y_pred_test12_2=ridge12_2.predict(x_test_scaled12)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train12_2=r2_score(y_train12,y_pred_train12_2)\n",
    "r2_ridge_test12_2=r2_score(y_test12,y_pred_test12_2)\n",
    "print(\"R2 de train: \", r2_ridge_train12_2)\n",
    "print(\"R2 de test: \", r2_ridge_test12_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf1091f1-1c17-4c53-b423-bd26549bdbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.772799934397899\n",
      "R2 de test:  0.8030251739579517\n"
     ]
    }
   ],
   "source": [
    "#Con alfa = 10, con xtrain_scaled y xtest_scaled\n",
    "ridge12_3= Ridge(alpha=10)\n",
    "ridge12_3.fit(x_train_scaled12, y_train12)\n",
    "#preparamos para sacar las r2 de ridge1 (nuestro modelo), sacando las y_pred, \n",
    "y_pred_train12_3=ridge12_3.predict(x_train_scaled12)\n",
    "y_pred_test12_3=ridge12_3.predict(x_test_scaled12)\n",
    "\n",
    "#sacamos r2\n",
    "r2_ridge_train12_3=r2_score(y_train12,y_pred_train12_3)\n",
    "r2_ridge_test12_3=r2_score(y_test12,y_pred_test12_3)\n",
    "print(\"R2 de train: \", r2_ridge_train12_3)\n",
    "print(\"R2 de test: \", r2_ridge_test12_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae3295-04b3-4b43-8dab-c4a74d53ae07",
   "metadata": {},
   "source": [
    "Al observar las r2, considero que la mejor es la de lambda = 1, ya que, es la que presenta una mejor generalización de las 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3de1c-4bd5-40cd-8d5d-f9e418ea1ad8",
   "metadata": {},
   "source": [
    "## 2.1 Realiza una regresión tomando 'mpg' como salida y eliminando la columna 'model'. Crea columnas dummies para los factores 'cyl', 'gear' y 'carb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10c5b520-19cf-404b-83ff-c8c3d1945980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>cyl_4</th>\n",
       "      <th>cyl_6</th>\n",
       "      <th>cyl_8</th>\n",
       "      <th>gear_3</th>\n",
       "      <th>gear_4</th>\n",
       "      <th>gear_5</th>\n",
       "      <th>carb_1</th>\n",
       "      <th>carb_2</th>\n",
       "      <th>carb_3</th>\n",
       "      <th>carb_4</th>\n",
       "      <th>carb_6</th>\n",
       "      <th>carb_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.1</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.3</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.8</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.2</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.8</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.4</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.3</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.2</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.4</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.4</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.7</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.9</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.5</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.5</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.2</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.3</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.2</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg   disp   hp  drat     wt   qsec  vs  am  cyl_4  cyl_6  cyl_8  gear_3  \\\n",
       "0   21.0  160.0  110  3.90  2.620  16.46   0   1  False   True  False   False   \n",
       "1   21.0  160.0  110  3.90  2.875  17.02   0   1  False   True  False   False   \n",
       "2   22.8  108.0   93  3.85  2.320  18.61   1   1   True  False  False   False   \n",
       "3   21.4  258.0  110  3.08  3.215  19.44   1   0  False   True  False    True   \n",
       "4   18.7  360.0  175  3.15  3.440  17.02   0   0  False  False   True    True   \n",
       "5   18.1  225.0  105  2.76  3.460  20.22   1   0  False   True  False    True   \n",
       "6   14.3  360.0  245  3.21  3.570  15.84   0   0  False  False   True    True   \n",
       "7   24.4  146.7   62  3.69  3.190  20.00   1   0   True  False  False   False   \n",
       "8   22.8  140.8   95  3.92  3.150  22.90   1   0   True  False  False   False   \n",
       "9   19.2  167.6  123  3.92  3.440  18.30   1   0  False   True  False   False   \n",
       "10  17.8  167.6  123  3.92  3.440  18.90   1   0  False   True  False   False   \n",
       "11  16.4  275.8  180  3.07  4.070  17.40   0   0  False  False   True    True   \n",
       "12  17.3  275.8  180  3.07  3.730  17.60   0   0  False  False   True    True   \n",
       "13  15.2  275.8  180  3.07  3.780  18.00   0   0  False  False   True    True   \n",
       "14  10.4  472.0  205  2.93  5.250  17.98   0   0  False  False   True    True   \n",
       "15  10.4  460.0  215  3.00  5.424  17.82   0   0  False  False   True    True   \n",
       "16  14.7  440.0  230  3.23  5.345  17.42   0   0  False  False   True    True   \n",
       "17  32.4   78.7   66  4.08  2.200  19.47   1   1   True  False  False   False   \n",
       "18  30.4   75.7   52  4.93  1.615  18.52   1   1   True  False  False   False   \n",
       "19  33.9   71.1   65  4.22  1.835  19.90   1   1   True  False  False   False   \n",
       "20  21.5  120.1   97  3.70  2.465  20.01   1   0   True  False  False    True   \n",
       "21  15.5  318.0  150  2.76  3.520  16.87   0   0  False  False   True    True   \n",
       "22  15.2  304.0  150  3.15  3.435  17.30   0   0  False  False   True    True   \n",
       "23  13.3  350.0  245  3.73  3.840  15.41   0   0  False  False   True    True   \n",
       "24  19.2  400.0  175  3.08  3.845  17.05   0   0  False  False   True    True   \n",
       "25  27.3   79.0   66  4.08  1.935  18.90   1   1   True  False  False   False   \n",
       "26  26.0  120.3   91  4.43  2.140  16.70   0   1   True  False  False   False   \n",
       "27  30.4   95.1  113  3.77  1.513  16.90   1   1   True  False  False   False   \n",
       "28  15.8  351.0  264  4.22  3.170  14.50   0   1  False  False   True   False   \n",
       "29  19.7  145.0  175  3.62  2.770  15.50   0   1  False   True  False   False   \n",
       "30  15.0  301.0  335  3.54  3.570  14.60   0   1  False  False   True   False   \n",
       "31  21.4  121.0  109  4.11  2.780  18.60   1   1   True  False  False   False   \n",
       "\n",
       "    gear_4  gear_5  carb_1  carb_2  carb_3  carb_4  carb_6  carb_8  \n",
       "0     True   False   False   False   False    True   False   False  \n",
       "1     True   False   False   False   False    True   False   False  \n",
       "2     True   False    True   False   False   False   False   False  \n",
       "3    False   False    True   False   False   False   False   False  \n",
       "4    False   False   False    True   False   False   False   False  \n",
       "5    False   False    True   False   False   False   False   False  \n",
       "6    False   False   False   False   False    True   False   False  \n",
       "7     True   False   False    True   False   False   False   False  \n",
       "8     True   False   False    True   False   False   False   False  \n",
       "9     True   False   False   False   False    True   False   False  \n",
       "10    True   False   False   False   False    True   False   False  \n",
       "11   False   False   False   False    True   False   False   False  \n",
       "12   False   False   False   False    True   False   False   False  \n",
       "13   False   False   False   False    True   False   False   False  \n",
       "14   False   False   False   False   False    True   False   False  \n",
       "15   False   False   False   False   False    True   False   False  \n",
       "16   False   False   False   False   False    True   False   False  \n",
       "17    True   False    True   False   False   False   False   False  \n",
       "18    True   False   False    True   False   False   False   False  \n",
       "19    True   False    True   False   False   False   False   False  \n",
       "20   False   False    True   False   False   False   False   False  \n",
       "21   False   False   False    True   False   False   False   False  \n",
       "22   False   False   False    True   False   False   False   False  \n",
       "23   False   False   False   False   False    True   False   False  \n",
       "24   False   False   False    True   False   False   False   False  \n",
       "25    True   False    True   False   False   False   False   False  \n",
       "26   False    True   False    True   False   False   False   False  \n",
       "27   False    True   False    True   False   False   False   False  \n",
       "28   False    True   False   False   False    True   False   False  \n",
       "29   False    True   False   False   False   False    True   False  \n",
       "30   False    True   False   False   False   False   False    True  \n",
       "31    True   False   False    True   False   False   False   False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_dumm=pd.get_dummies(dat, columns=[\"cyl\",\"gear\",\"carb\"])\n",
    "dat_dumm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968375b7-29a1-4d6e-b9fe-e10993d6b3b1",
   "metadata": {},
   "source": [
    "- Calcula el R2 e interpreta los signos de los betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b64b53db-2229-4529-a145-0f6abb4c1afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>0.000124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:42</td>     <th>  Log-Likelihood:    </th> <td> -66.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   167.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    15</td>      <th>  BIC:               </th> <td>   192.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   14.4937</td> <td>   10.672</td> <td>    1.358</td> <td> 0.195</td> <td>   -8.254</td> <td>   37.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0355</td> <td>    0.032</td> <td>    1.114</td> <td> 0.283</td> <td>   -0.032</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0705</td> <td>    0.039</td> <td>   -1.788</td> <td> 0.094</td> <td>   -0.155</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.1828</td> <td>    2.483</td> <td>    0.476</td> <td> 0.641</td> <td>   -4.111</td> <td>    6.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -4.5298</td> <td>    2.539</td> <td>   -1.784</td> <td> 0.095</td> <td>   -9.941</td> <td>    0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3678</td> <td>    0.935</td> <td>    0.393</td> <td> 0.700</td> <td>   -1.626</td> <td>    2.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    1.9309</td> <td>    2.871</td> <td>    0.672</td> <td> 0.512</td> <td>   -4.189</td> <td>    8.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    1.2121</td> <td>    3.214</td> <td>    0.377</td> <td> 0.711</td> <td>   -5.637</td> <td>    8.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    5.8262</td> <td>    5.651</td> <td>    1.031</td> <td> 0.319</td> <td>   -6.218</td> <td>   17.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    3.1775</td> <td>    3.526</td> <td>    0.901</td> <td> 0.382</td> <td>   -4.337</td> <td>   10.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    5.4900</td> <td>    4.884</td> <td>    1.124</td> <td> 0.279</td> <td>   -4.920</td> <td>   15.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    3.6170</td> <td>    3.548</td> <td>    1.020</td> <td> 0.324</td> <td>   -3.945</td> <td>   11.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    4.7313</td> <td>    4.622</td> <td>    1.024</td> <td> 0.322</td> <td>   -5.120</td> <td>   14.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    6.1454</td> <td>    4.099</td> <td>    1.499</td> <td> 0.155</td> <td>   -2.591</td> <td>   14.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0577</td> <td>    3.844</td> <td>   -0.015</td> <td> 0.988</td> <td>   -8.250</td> <td>    8.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -1.0370</td> <td>    2.923</td> <td>   -0.355</td> <td> 0.728</td> <td>   -7.267</td> <td>    5.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    2.9420</td> <td>    3.393</td> <td>    0.867</td> <td> 0.400</td> <td>   -4.291</td> <td>   10.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    1.0338</td> <td>    2.628</td> <td>    0.393</td> <td> 0.700</td> <td>   -4.567</td> <td>    6.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    4.4199</td> <td>    4.041</td> <td>    1.094</td> <td> 0.291</td> <td>   -4.193</td> <td>   13.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    7.1927</td> <td>    5.924</td> <td>    1.214</td> <td> 0.243</td> <td>   -5.434</td> <td>   19.820</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.468</td> <th>  Durbin-Watson:     </th> <td>   2.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.291</td> <th>  Jarque-Bera (JB):  </th> <td>   1.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.576</td> <th>  Prob(JB):          </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.009</td> <th>  Cond. No.          </th> <td>1.21e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.04e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.893   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.779   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     7.830   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &  0.000124   \\\\\n",
       "\\textbf{Time:}             &     07:11:42     & \\textbf{  Log-Likelihood:    } &   -66.608   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     167.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          15      & \\textbf{  BIC:               } &     192.1   \\\\\n",
       "\\textbf{Df Model:}         &          16      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      14.4937  &       10.672     &     1.358  &         0.195        &       -8.254    &       37.241     \\\\\n",
       "\\textbf{x1}    &       0.0355  &        0.032     &     1.114  &         0.283        &       -0.032    &        0.104     \\\\\n",
       "\\textbf{x2}    &      -0.0705  &        0.039     &    -1.788  &         0.094        &       -0.155    &        0.014     \\\\\n",
       "\\textbf{x3}    &       1.1828  &        2.483     &     0.476  &         0.641        &       -4.111    &        6.476     \\\\\n",
       "\\textbf{x4}    &      -4.5298  &        2.539     &    -1.784  &         0.095        &       -9.941    &        0.881     \\\\\n",
       "\\textbf{x5}    &       0.3678  &        0.935     &     0.393  &         0.700        &       -1.626    &        2.362     \\\\\n",
       "\\textbf{x6}    &       1.9309  &        2.871     &     0.672  &         0.512        &       -4.189    &        8.051     \\\\\n",
       "\\textbf{x7}    &       1.2121  &        3.214     &     0.377  &         0.711        &       -5.637    &        8.062     \\\\\n",
       "\\textbf{x8}    &       5.8262  &        5.651     &     1.031  &         0.319        &       -6.218    &       17.871     \\\\\n",
       "\\textbf{x9}    &       3.1775  &        3.526     &     0.901  &         0.382        &       -4.337    &       10.692     \\\\\n",
       "\\textbf{x10}   &       5.4900  &        4.884     &     1.124  &         0.279        &       -4.920    &       15.900     \\\\\n",
       "\\textbf{x11}   &       3.6170  &        3.548     &     1.020  &         0.324        &       -3.945    &       11.179     \\\\\n",
       "\\textbf{x12}   &       4.7313  &        4.622     &     1.024  &         0.322        &       -5.120    &       14.583     \\\\\n",
       "\\textbf{x13}   &       6.1454  &        4.099     &     1.499  &         0.155        &       -2.591    &       14.882     \\\\\n",
       "\\textbf{x14}   &      -0.0577  &        3.844     &    -0.015  &         0.988        &       -8.250    &        8.135     \\\\\n",
       "\\textbf{x15}   &      -1.0370  &        2.923     &    -0.355  &         0.728        &       -7.267    &        5.193     \\\\\n",
       "\\textbf{x16}   &       2.9420  &        3.393     &     0.867  &         0.400        &       -4.291    &       10.175     \\\\\n",
       "\\textbf{x17}   &       1.0338  &        2.628     &     0.393  &         0.700        &       -4.567    &        6.634     \\\\\n",
       "\\textbf{x18}   &       4.4199  &        4.041     &     1.094  &         0.291        &       -4.193    &       13.033     \\\\\n",
       "\\textbf{x19}   &       7.1927  &        5.924     &     1.214  &         0.243        &       -5.434    &       19.820     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.468 & \\textbf{  Durbin-Watson:     } &    2.105  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.291 & \\textbf{  Jarque-Bera (JB):  } &    1.772  \\\\\n",
       "\\textbf{Skew:}          &  0.576 & \\textbf{  Prob(JB):          } &    0.412  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.009 & \\textbf{  Cond. No.          } & 1.21e+19  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 2.04e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.893\n",
       "Model:                            OLS   Adj. R-squared:                  0.779\n",
       "Method:                 Least Squares   F-statistic:                     7.830\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):           0.000124\n",
       "Time:                        07:11:42   Log-Likelihood:                -66.608\n",
       "No. Observations:                  32   AIC:                             167.2\n",
       "Df Residuals:                      15   BIC:                             192.1\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         14.4937     10.672      1.358      0.195      -8.254      37.241\n",
       "x1             0.0355      0.032      1.114      0.283      -0.032       0.104\n",
       "x2            -0.0705      0.039     -1.788      0.094      -0.155       0.014\n",
       "x3             1.1828      2.483      0.476      0.641      -4.111       6.476\n",
       "x4            -4.5298      2.539     -1.784      0.095      -9.941       0.881\n",
       "x5             0.3678      0.935      0.393      0.700      -1.626       2.362\n",
       "x6             1.9309      2.871      0.672      0.512      -4.189       8.051\n",
       "x7             1.2121      3.214      0.377      0.711      -5.637       8.062\n",
       "x8             5.8262      5.651      1.031      0.319      -6.218      17.871\n",
       "x9             3.1775      3.526      0.901      0.382      -4.337      10.692\n",
       "x10            5.4900      4.884      1.124      0.279      -4.920      15.900\n",
       "x11            3.6170      3.548      1.020      0.324      -3.945      11.179\n",
       "x12            4.7313      4.622      1.024      0.322      -5.120      14.583\n",
       "x13            6.1454      4.099      1.499      0.155      -2.591      14.882\n",
       "x14           -0.0577      3.844     -0.015      0.988      -8.250       8.135\n",
       "x15           -1.0370      2.923     -0.355      0.728      -7.267       5.193\n",
       "x16            2.9420      3.393      0.867      0.400      -4.291      10.175\n",
       "x17            1.0338      2.628      0.393      0.700      -4.567       6.634\n",
       "x18            4.4199      4.041      1.094      0.291      -4.193      13.033\n",
       "x19            7.1927      5.924      1.214      0.243      -5.434      19.820\n",
       "==============================================================================\n",
       "Omnibus:                        2.468   Durbin-Watson:                   2.105\n",
       "Prob(Omnibus):                  0.291   Jarque-Bera (JB):                1.772\n",
       "Skew:                           0.576   Prob(JB):                        0.412\n",
       "Kurtosis:                       3.009   Cond. No.                     1.21e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.04e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2=dat_dumm.iloc[:,1:].astype(float).values\n",
    "y2=dat_dumm.mpg\n",
    "n=len(y2)\n",
    "unos=np.ones([n,1])\n",
    "X2=np.hstack([unos,x2])\n",
    "ols=sm.OLS(y2,X2)\n",
    "resultados=ols.fit()\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e45e2-dea0-4958-ae97-a35a8b7e6092",
   "metadata": {},
   "source": [
    "En esta regresión linea sin escalar ni entrenar, donde convertimos a dummies parte de nuestros datos, podemos ver que nuestro modelo presenta más variables que se relación con el incremento de mpg. Además, de tener un r2 de 0.893, presentando lo que se puede explicar mediante el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a723e6-f89f-4458-aa23-4cfb608680e7",
   "metadata": {},
   "source": [
    "- Realiza un train-test-split donde se use el 40% de los datos para entrenar. Calcula el R2 de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d8d62bc-e0d9-4fbe-81b0-3a453bd9bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos los datos\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.4, random_state=137)\n",
    "\n",
    "#escalamos los xtrain y xtest\n",
    "scaler=StandardScaler().fit(x_train2)\n",
    "\n",
    "x_train_scaled2=scaler.transform(x_train2)\n",
    "x_test_scaled2=scaler.transform(x_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4310fc9f-7778-449d-af3f-3b2e726f50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munoz\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=19\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th>  <td>0.0253</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:43</td>     <th>  Log-Likelihood:    </th> <td> -20.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    19</td>      <th>  AIC:               </th> <td>   72.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     3</td>      <th>  BIC:               </th> <td>   87.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   18.4947</td> <td>    0.404</td> <td>   45.797</td> <td> 0.000</td> <td>   17.210</td> <td>   19.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-2.234e-14</td> <td> 1.96e-14</td> <td>   -1.141</td> <td> 0.337</td> <td>-8.46e-14</td> <td>    4e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -14.4986</td> <td>    7.624</td> <td>   -1.902</td> <td> 0.153</td> <td>  -38.762</td> <td>    9.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -3.3690</td> <td>    3.213</td> <td>   -1.049</td> <td> 0.371</td> <td>  -13.594</td> <td>    6.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.1669</td> <td>    3.561</td> <td>   -0.047</td> <td> 0.966</td> <td>  -11.499</td> <td>   11.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    4.4120</td> <td>    3.492</td> <td>    1.263</td> <td> 0.296</td> <td>   -6.702</td> <td>   15.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.5129</td> <td>    1.731</td> <td>   -0.296</td> <td> 0.786</td> <td>   -6.022</td> <td>    4.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -2.3637</td> <td>    2.134</td> <td>   -1.108</td> <td> 0.349</td> <td>   -9.154</td> <td>    4.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.0955</td> <td>    1.784</td> <td>   -0.614</td> <td> 0.583</td> <td>   -6.773</td> <td>    4.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.7602</td> <td>    2.173</td> <td>    0.350</td> <td> 0.750</td> <td>   -6.155</td> <td>    7.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -3.3021</td> <td>    1.507</td> <td>   -2.191</td> <td> 0.116</td> <td>   -8.099</td> <td>    1.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    1.7608</td> <td>    2.908</td> <td>    0.605</td> <td> 0.588</td> <td>   -7.495</td> <td>   11.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.4611</td> <td>    1.985</td> <td>    0.232</td> <td> 0.831</td> <td>   -5.857</td> <td>    6.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -2.2382</td> <td>    1.657</td> <td>   -1.350</td> <td> 0.270</td> <td>   -7.512</td> <td>    3.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    2.2217</td> <td>    1.152</td> <td>    1.928</td> <td> 0.149</td> <td>   -1.445</td> <td>    5.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    1.5335</td> <td>    1.309</td> <td>    1.172</td> <td> 0.326</td> <td>   -2.632</td> <td>    5.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -1.7334</td> <td>    0.777</td> <td>   -2.231</td> <td> 0.112</td> <td>   -4.206</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -2.5749</td> <td>    1.361</td> <td>   -1.891</td> <td> 0.155</td> <td>   -6.907</td> <td>    1.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    2.6488</td> <td>    1.456</td> <td>    1.819</td> <td> 0.166</td> <td>   -1.985</td> <td>    7.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0164</td> <td>    2.228</td> <td>   -0.007</td> <td> 0.995</td> <td>   -7.108</td> <td>    7.075</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.711</td> <th>  Durbin-Watson:     </th> <td>   1.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.258</td> <th>  Jarque-Bera (JB):  </th> <td>   1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.503</td> <th>  Prob(JB):          </th> <td>   0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.610</td> <th>  Cond. No.          </th> <td>6.70e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The input rank is higher than the number of observations.<br/>[3] The smallest eigenvalue is 3.19e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.986   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.916   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     14.15   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &   0.0253    \\\\\n",
       "\\textbf{Time:}             &     07:11:43     & \\textbf{  Log-Likelihood:    } &   -20.169   \\\\\n",
       "\\textbf{No. Observations:} &          19      & \\textbf{  AIC:               } &     72.34   \\\\\n",
       "\\textbf{Df Residuals:}     &           3      & \\textbf{  BIC:               } &     87.45   \\\\\n",
       "\\textbf{Df Model:}         &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      18.4947  &        0.404     &    45.797  &         0.000        &       17.210    &       19.780     \\\\\n",
       "\\textbf{x1}    &   -2.234e-14  &     1.96e-14     &    -1.141  &         0.337        &    -8.46e-14    &        4e-14     \\\\\n",
       "\\textbf{x2}    &     -14.4986  &        7.624     &    -1.902  &         0.153        &      -38.762    &        9.765     \\\\\n",
       "\\textbf{x3}    &      -3.3690  &        3.213     &    -1.049  &         0.371        &      -13.594    &        6.856     \\\\\n",
       "\\textbf{x4}    &      -0.1669  &        3.561     &    -0.047  &         0.966        &      -11.499    &       11.165     \\\\\n",
       "\\textbf{x5}    &       4.4120  &        3.492     &     1.263  &         0.296        &       -6.702    &       15.526     \\\\\n",
       "\\textbf{x6}    &      -0.5129  &        1.731     &    -0.296  &         0.786        &       -6.022    &        4.996     \\\\\n",
       "\\textbf{x7}    &      -2.3637  &        2.134     &    -1.108  &         0.349        &       -9.154    &        4.426     \\\\\n",
       "\\textbf{x8}    &      -1.0955  &        1.784     &    -0.614  &         0.583        &       -6.773    &        4.582     \\\\\n",
       "\\textbf{x9}    &       0.7602  &        2.173     &     0.350  &         0.750        &       -6.155    &        7.675     \\\\\n",
       "\\textbf{x10}   &      -3.3021  &        1.507     &    -2.191  &         0.116        &       -8.099    &        1.494     \\\\\n",
       "\\textbf{x11}   &       1.7608  &        2.908     &     0.605  &         0.588        &       -7.495    &       11.016     \\\\\n",
       "\\textbf{x12}   &       0.4611  &        1.985     &     0.232  &         0.831        &       -5.857    &        6.779     \\\\\n",
       "\\textbf{x13}   &      -2.2382  &        1.657     &    -1.350  &         0.270        &       -7.512    &        3.036     \\\\\n",
       "\\textbf{x14}   &       2.2217  &        1.152     &     1.928  &         0.149        &       -1.445    &        5.889     \\\\\n",
       "\\textbf{x15}   &       1.5335  &        1.309     &     1.172  &         0.326        &       -2.632    &        5.699     \\\\\n",
       "\\textbf{x16}   &      -1.7334  &        0.777     &    -2.231  &         0.112        &       -4.206    &        0.739     \\\\\n",
       "\\textbf{x17}   &      -2.5749  &        1.361     &    -1.891  &         0.155        &       -6.907    &        1.758     \\\\\n",
       "\\textbf{x18}   &       2.6488  &        1.456     &     1.819  &         0.166        &       -1.985    &        7.283     \\\\\n",
       "\\textbf{x19}   &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{x20}   &      -0.0164  &        2.228     &    -0.007  &         0.995        &       -7.108    &        7.075     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.711 & \\textbf{  Durbin-Watson:     } &    1.924  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.258 & \\textbf{  Jarque-Bera (JB):  } &    1.095  \\\\\n",
       "\\textbf{Skew:}          &  0.503 & \\textbf{  Prob(JB):          } &    0.578  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.610 & \\textbf{  Cond. No.          } & 6.70e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The input rank is higher than the number of observations. \\newline\n",
       " [3] The smallest eigenvalue is 3.19e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.986\n",
       "Model:                            OLS   Adj. R-squared:                  0.916\n",
       "Method:                 Least Squares   F-statistic:                     14.15\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):             0.0253\n",
       "Time:                        07:11:43   Log-Likelihood:                -20.169\n",
       "No. Observations:                  19   AIC:                             72.34\n",
       "Df Residuals:                       3   BIC:                             87.45\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         18.4947      0.404     45.797      0.000      17.210      19.780\n",
       "x1         -2.234e-14   1.96e-14     -1.141      0.337   -8.46e-14       4e-14\n",
       "x2           -14.4986      7.624     -1.902      0.153     -38.762       9.765\n",
       "x3            -3.3690      3.213     -1.049      0.371     -13.594       6.856\n",
       "x4            -0.1669      3.561     -0.047      0.966     -11.499      11.165\n",
       "x5             4.4120      3.492      1.263      0.296      -6.702      15.526\n",
       "x6            -0.5129      1.731     -0.296      0.786      -6.022       4.996\n",
       "x7            -2.3637      2.134     -1.108      0.349      -9.154       4.426\n",
       "x8            -1.0955      1.784     -0.614      0.583      -6.773       4.582\n",
       "x9             0.7602      2.173      0.350      0.750      -6.155       7.675\n",
       "x10           -3.3021      1.507     -2.191      0.116      -8.099       1.494\n",
       "x11            1.7608      2.908      0.605      0.588      -7.495      11.016\n",
       "x12            0.4611      1.985      0.232      0.831      -5.857       6.779\n",
       "x13           -2.2382      1.657     -1.350      0.270      -7.512       3.036\n",
       "x14            2.2217      1.152      1.928      0.149      -1.445       5.889\n",
       "x15            1.5335      1.309      1.172      0.326      -2.632       5.699\n",
       "x16           -1.7334      0.777     -2.231      0.112      -4.206       0.739\n",
       "x17           -2.5749      1.361     -1.891      0.155      -6.907       1.758\n",
       "x18            2.6488      1.456      1.819      0.166      -1.985       7.283\n",
       "x19                 0          0        nan        nan           0           0\n",
       "x20           -0.0164      2.228     -0.007      0.995      -7.108       7.075\n",
       "==============================================================================\n",
       "Omnibus:                        2.711   Durbin-Watson:                   1.924\n",
       "Prob(Omnibus):                  0.258   Jarque-Bera (JB):                1.095\n",
       "Skew:                           0.503   Prob(JB):                        0.578\n",
       "Kurtosis:                       3.610   Cond. No.                     6.70e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The input rank is higher than the number of observations.\n",
       "[3] The smallest eigenvalue is 3.19e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos la regresión lineal\n",
    "x_train_e2= sm.add_constant(x_train_scaled2)\n",
    "resultado= sm.OLS(y_train2,x_train_e2).fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140ae16-37da-4db8-9e10-0d85e787e075",
   "metadata": {},
   "source": [
    "Al realizar el escalamiento y sacar las x_train y x_test, vemos que nuestra r2 incremento a un 0.986, lo cual nos indica el buen escalamiento que tuvo nuestro modelo, pues explica casi el modelo completo. Así mismo, tuvimos variables que ahora con su relación con y no es en aumento, sino en disminución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa65e082-adff-4e82-9de1-f5ddbc79871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.9860599593190703\n",
      "R2 de test:  -1.7261974546344292\n"
     ]
    }
   ],
   "source": [
    "#Sacamos lor R2 de x_train y x_test\n",
    "\n",
    "#preparamos x_test\n",
    "x_test_e2=sm.add_constant(x_test_scaled2, has_constant='add')\n",
    "y_pred2=resultado.predict(x_test_e2)\n",
    "#calculamos r2 de xtrain\n",
    "r2_train2=resultado.rsquared\n",
    "print(\"R2 de train: \",r2_train2)\n",
    "\n",
    "#calculamos r2 de xtest\n",
    "r2_test2=r2_score(y_test2, y_pred2)\n",
    "print(\"R2 de test: \",r2_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312e0e1-0648-467f-91ac-f4917a44675c",
   "metadata": {},
   "source": [
    "Sacando las r2 de train y test, podemos ver que hay overfitting, por lo que, el modelo no es tan bueno como se había presentado en la regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bede00-24f8-413b-acfb-3f7dcc4b5b00",
   "metadata": {},
   "source": [
    "## 2.2 Repite el ejercicio anterior usando 'qsec' como salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcdc96f-f65c-4a49-8cc8-380ee9b387c9",
   "metadata": {},
   "source": [
    "- Calcula el R2 e interpreta los signos de los betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e68f30e-3d78-4604-ae91-5ef552318ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>qsec</td>       <th>  R-squared:         </th> <td>   0.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>4.35e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:11:45</td>     <th>  Log-Likelihood:    </th> <td> -25.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   84.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    15</td>      <th>  BIC:               </th> <td>   109.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.9157</td> <td>    2.339</td> <td>    3.385</td> <td> 0.004</td> <td>    2.931</td> <td>   12.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0277</td> <td>    0.071</td> <td>    0.393</td> <td> 0.700</td> <td>   -0.123</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0035</td> <td>    0.009</td> <td>    0.389</td> <td> 0.703</td> <td>   -0.016</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0021</td> <td>    0.012</td> <td>   -0.173</td> <td> 0.865</td> <td>   -0.027</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.1079</td> <td>    0.687</td> <td>    0.157</td> <td> 0.877</td> <td>   -1.356</td> <td>    1.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.8105</td> <td>    0.739</td> <td>    1.097</td> <td> 0.290</td> <td>   -0.764</td> <td>    2.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2657</td> <td>    0.797</td> <td>    0.333</td> <td> 0.744</td> <td>   -1.434</td> <td>    1.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -1.6943</td> <td>    0.771</td> <td>   -2.197</td> <td> 0.044</td> <td>   -3.338</td> <td>   -0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    3.9957</td> <td>    1.231</td> <td>    3.247</td> <td> 0.005</td> <td>    1.373</td> <td>    6.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    2.8913</td> <td>    0.656</td> <td>    4.405</td> <td> 0.001</td> <td>    1.492</td> <td>    4.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    1.0288</td> <td>    1.371</td> <td>    0.750</td> <td> 0.465</td> <td>   -1.894</td> <td>    3.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    2.1337</td> <td>    0.843</td> <td>    2.530</td> <td> 0.023</td> <td>    0.336</td> <td>    3.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    3.4660</td> <td>    0.961</td> <td>    3.608</td> <td> 0.003</td> <td>    1.418</td> <td>    5.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    2.3160</td> <td>    1.049</td> <td>    2.209</td> <td> 0.043</td> <td>    0.081</td> <td>    4.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    2.3040</td> <td>    0.872</td> <td>    2.642</td> <td> 0.018</td> <td>    0.445</td> <td>    4.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    1.4696</td> <td>    0.711</td> <td>    2.066</td> <td> 0.057</td> <td>   -0.046</td> <td>    2.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    2.0747</td> <td>    0.791</td> <td>    2.624</td> <td> 0.019</td> <td>    0.390</td> <td>    3.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.3570</td> <td>    0.719</td> <td>    0.496</td> <td> 0.627</td> <td>   -1.176</td> <td>    1.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.7388</td> <td>    1.137</td> <td>    0.650</td> <td> 0.526</td> <td>   -1.685</td> <td>    3.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.9717</td> <td>    1.686</td> <td>    0.576</td> <td> 0.573</td> <td>   -2.623</td> <td>    4.566</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.619</td> <th>  Durbin-Watson:     </th> <td>   2.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  16.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.924</td> <th>  Prob(JB):          </th> <td>0.000205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.054</td> <th>  Cond. No.          </th> <td>7.46e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.33e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       qsec       & \\textbf{  R-squared:         } &     0.908   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.810   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     9.283   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &  4.35e-05   \\\\\n",
       "\\textbf{Time:}             &     07:11:45     & \\textbf{  Log-Likelihood:    } &   -25.252   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     84.50   \\\\\n",
       "\\textbf{Df Residuals:}     &          15      & \\textbf{  BIC:               } &     109.4   \\\\\n",
       "\\textbf{Df Model:}         &          16      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       7.9157  &        2.339     &     3.385  &         0.004        &        2.931    &       12.900     \\\\\n",
       "\\textbf{x1}    &       0.0277  &        0.071     &     0.393  &         0.700        &       -0.123    &        0.178     \\\\\n",
       "\\textbf{x2}    &       0.0035  &        0.009     &     0.389  &         0.703        &       -0.016    &        0.023     \\\\\n",
       "\\textbf{x3}    &      -0.0021  &        0.012     &    -0.173  &         0.865        &       -0.027    &        0.023     \\\\\n",
       "\\textbf{x4}    &       0.1079  &        0.687     &     0.157  &         0.877        &       -1.356    &        1.571     \\\\\n",
       "\\textbf{x5}    &       0.8105  &        0.739     &     1.097  &         0.290        &       -0.764    &        2.385     \\\\\n",
       "\\textbf{x6}    &       0.2657  &        0.797     &     0.333  &         0.744        &       -1.434    &        1.965     \\\\\n",
       "\\textbf{x7}    &      -1.6943  &        0.771     &    -2.197  &         0.044        &       -3.338    &       -0.050     \\\\\n",
       "\\textbf{x8}    &       3.9957  &        1.231     &     3.247  &         0.005        &        1.373    &        6.619     \\\\\n",
       "\\textbf{x9}    &       2.8913  &        0.656     &     4.405  &         0.001        &        1.492    &        4.290     \\\\\n",
       "\\textbf{x10}   &       1.0288  &        1.371     &     0.750  &         0.465        &       -1.894    &        3.951     \\\\\n",
       "\\textbf{x11}   &       2.1337  &        0.843     &     2.530  &         0.023        &        0.336    &        3.931     \\\\\n",
       "\\textbf{x12}   &       3.4660  &        0.961     &     3.608  &         0.003        &        1.418    &        5.514     \\\\\n",
       "\\textbf{x13}   &       2.3160  &        1.049     &     2.209  &         0.043        &        0.081    &        4.551     \\\\\n",
       "\\textbf{x14}   &       2.3040  &        0.872     &     2.642  &         0.018        &        0.445    &        4.163     \\\\\n",
       "\\textbf{x15}   &       1.4696  &        0.711     &     2.066  &         0.057        &       -0.046    &        2.985     \\\\\n",
       "\\textbf{x16}   &       2.0747  &        0.791     &     2.624  &         0.019        &        0.390    &        3.760     \\\\\n",
       "\\textbf{x17}   &       0.3570  &        0.719     &     0.496  &         0.627        &       -1.176    &        1.890     \\\\\n",
       "\\textbf{x18}   &       0.7388  &        1.137     &     0.650  &         0.526        &       -1.685    &        3.163     \\\\\n",
       "\\textbf{x19}   &       0.9717  &        1.686     &     0.576  &         0.573        &       -2.623    &        4.566     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 12.619 & \\textbf{  Durbin-Watson:     } &    2.588  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.002 & \\textbf{  Jarque-Bera (JB):  } &   16.989  \\\\\n",
       "\\textbf{Skew:}          &  0.924 & \\textbf{  Prob(JB):          } & 0.000205  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.054 & \\textbf{  Cond. No.          } & 7.46e+18  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 5.33e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   qsec   R-squared:                       0.908\n",
       "Model:                            OLS   Adj. R-squared:                  0.810\n",
       "Method:                 Least Squares   F-statistic:                     9.283\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):           4.35e-05\n",
       "Time:                        07:11:45   Log-Likelihood:                -25.252\n",
       "No. Observations:                  32   AIC:                             84.50\n",
       "Df Residuals:                      15   BIC:                             109.4\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.9157      2.339      3.385      0.004       2.931      12.900\n",
       "x1             0.0277      0.071      0.393      0.700      -0.123       0.178\n",
       "x2             0.0035      0.009      0.389      0.703      -0.016       0.023\n",
       "x3            -0.0021      0.012     -0.173      0.865      -0.027       0.023\n",
       "x4             0.1079      0.687      0.157      0.877      -1.356       1.571\n",
       "x5             0.8105      0.739      1.097      0.290      -0.764       2.385\n",
       "x6             0.2657      0.797      0.333      0.744      -1.434       1.965\n",
       "x7            -1.6943      0.771     -2.197      0.044      -3.338      -0.050\n",
       "x8             3.9957      1.231      3.247      0.005       1.373       6.619\n",
       "x9             2.8913      0.656      4.405      0.001       1.492       4.290\n",
       "x10            1.0288      1.371      0.750      0.465      -1.894       3.951\n",
       "x11            2.1337      0.843      2.530      0.023       0.336       3.931\n",
       "x12            3.4660      0.961      3.608      0.003       1.418       5.514\n",
       "x13            2.3160      1.049      2.209      0.043       0.081       4.551\n",
       "x14            2.3040      0.872      2.642      0.018       0.445       4.163\n",
       "x15            1.4696      0.711      2.066      0.057      -0.046       2.985\n",
       "x16            2.0747      0.791      2.624      0.019       0.390       3.760\n",
       "x17            0.3570      0.719      0.496      0.627      -1.176       1.890\n",
       "x18            0.7388      1.137      0.650      0.526      -1.685       3.163\n",
       "x19            0.9717      1.686      0.576      0.573      -2.623       4.566\n",
       "==============================================================================\n",
       "Omnibus:                       12.619   Durbin-Watson:                   2.588\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.989\n",
       "Skew:                           0.924   Prob(JB):                     0.000205\n",
       "Kurtosis:                       6.054   Cond. No.                     7.46e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.33e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_22=dat_dumm.drop(columns=[\"qsec\"]).astype(float).values.reshape(-1,19)\n",
    "y_22=dat_dumm.qsec\n",
    "n=len(y_22)\n",
    "unos=np.ones([n,1])\n",
    "X_22=np.hstack([unos,x_22])\n",
    "ols=sm.OLS(y_22,X_22)\n",
    "resultados=ols.fit()\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bce316-0395-4f5f-8354-46f09baa4906",
   "metadata": {},
   "source": [
    "En este modelo sin escalar ni entrenar, vemos que tenemos un r2 de 0.908, lo cual es bueno porque explica la gran mayoría de los datos. También vemos que la relación entre las variables con y en mayormente positiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddcd6b-b4e1-437a-9173-57f4762f2027",
   "metadata": {},
   "source": [
    "- Realiza un train-test-split donde se use el 40% de los datos para entrenar. Calcula el R2 de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9694679e-2a72-4c03-bcbf-07f880578bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos los datos\n",
    "x_train22, x_test22, y_train22, y_test22 = train_test_split(X_22, y_22, test_size=0.4, random_state=137)\n",
    "\n",
    "#escalamos los xtrain y xtest\n",
    "scaler=StandardScaler().fit(x_train22)\n",
    "\n",
    "x_train_scaled22=scaler.transform(x_train22)\n",
    "x_test_scaled22=scaler.transform(x_test22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79edbf77-25dd-42ab-b89a-2848f0d24c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munoz\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=19\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>qsec</td>       <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Sep 2025</td> <th>  Prob (F-statistic):</th>  <td> 0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:10:31</td>     <th>  Log-Likelihood:    </th> <td> -11.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    19</td>      <th>  AIC:               </th> <td>   54.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     3</td>      <th>  BIC:               </th> <td>   69.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   17.8511</td> <td>    0.255</td> <td>   70.116</td> <td> 0.000</td> <td>   17.041</td> <td>   18.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-3.193e-16</td> <td> 1.15e-14</td> <td>   -0.028</td> <td> 0.980</td> <td>-3.69e-14</td> <td> 3.62e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.6298</td> <td>    2.125</td> <td>   -0.296</td> <td> 0.786</td> <td>   -7.394</td> <td>    6.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.1599</td> <td>    7.107</td> <td>    0.163</td> <td> 0.881</td> <td>  -21.456</td> <td>   23.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.5011</td> <td>    2.350</td> <td>   -0.213</td> <td> 0.845</td> <td>   -7.980</td> <td>    6.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.4781</td> <td>    2.077</td> <td>    0.712</td> <td> 0.528</td> <td>   -5.133</td> <td>    8.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.2834</td> <td>    2.720</td> <td>    0.104</td> <td> 0.924</td> <td>   -8.373</td> <td>    8.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -1.2929</td> <td>    1.411</td> <td>   -0.916</td> <td> 0.427</td> <td>   -5.785</td> <td>    3.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.5616</td> <td>    0.782</td> <td>   -1.998</td> <td> 0.140</td> <td>   -4.049</td> <td>    0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    1.7809</td> <td>    0.946</td> <td>    1.882</td> <td> 0.156</td> <td>   -1.231</td> <td>    4.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.4684</td> <td>    1.508</td> <td>    0.311</td> <td> 0.776</td> <td>   -4.331</td> <td>    5.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -1.9343</td> <td>    1.589</td> <td>   -1.217</td> <td> 0.311</td> <td>   -6.991</td> <td>    3.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.2972</td> <td>    1.251</td> <td>    0.238</td> <td> 0.828</td> <td>   -3.684</td> <td>    4.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.2901</td> <td>    1.314</td> <td>   -0.221</td> <td> 0.839</td> <td>   -4.473</td> <td>    3.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0371</td> <td>    1.087</td> <td>   -0.034</td> <td> 0.975</td> <td>   -3.496</td> <td>    3.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.6935</td> <td>    0.912</td> <td>    0.760</td> <td> 0.502</td> <td>   -2.210</td> <td>    3.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0302</td> <td>    0.799</td> <td>   -0.038</td> <td> 0.972</td> <td>   -2.571</td> <td>    2.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.2974</td> <td>    1.259</td> <td>    0.236</td> <td> 0.829</td> <td>   -3.710</td> <td>    4.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.7588</td> <td>    1.257</td> <td>   -0.604</td> <td> 0.589</td> <td>   -4.759</td> <td>    3.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.2633</td> <td>    1.397</td> <td>    0.189</td> <td> 0.862</td> <td>   -4.181</td> <td>    4.708</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.980</td> <th>  Durbin-Watson:     </th> <td>   2.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.030</td> <th>  Jarque-Bera (JB):  </th> <td>   5.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.482</td> <th>  Prob(JB):          </th> <td>  0.0548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.531</td> <th>  Cond. No.          </th> <td>9.75e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The input rank is higher than the number of observations.<br/>[3] The smallest eigenvalue is 1.61e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       qsec       & \\textbf{  R-squared:         } &     0.947   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.683   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     3.583   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Sep 2025 & \\textbf{  Prob (F-statistic):} &    0.160    \\\\\n",
       "\\textbf{Time:}             &     08:10:31     & \\textbf{  Log-Likelihood:    } &   -11.403   \\\\\n",
       "\\textbf{No. Observations:} &          19      & \\textbf{  AIC:               } &     54.81   \\\\\n",
       "\\textbf{Df Residuals:}     &           3      & \\textbf{  BIC:               } &     69.92   \\\\\n",
       "\\textbf{Df Model:}         &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      17.8511  &        0.255     &    70.116  &         0.000        &       17.041    &       18.661     \\\\\n",
       "\\textbf{x1}    &   -3.193e-16  &     1.15e-14     &    -0.028  &         0.980        &    -3.69e-14    &     3.62e-14     \\\\\n",
       "\\textbf{x2}    &      -0.6298  &        2.125     &    -0.296  &         0.786        &       -7.394    &        6.134     \\\\\n",
       "\\textbf{x3}    &       1.1599  &        7.107     &     0.163  &         0.881        &      -21.456    &       23.776     \\\\\n",
       "\\textbf{x4}    &      -0.5011  &        2.350     &    -0.213  &         0.845        &       -7.980    &        6.978     \\\\\n",
       "\\textbf{x5}    &       1.4781  &        2.077     &     0.712  &         0.528        &       -5.133    &        8.089     \\\\\n",
       "\\textbf{x6}    &       0.2834  &        2.720     &     0.104  &         0.924        &       -8.373    &        8.940     \\\\\n",
       "\\textbf{x7}    &      -1.2929  &        1.411     &    -0.916  &         0.427        &       -5.785    &        3.199     \\\\\n",
       "\\textbf{x8}    &      -1.5616  &        0.782     &    -1.998  &         0.140        &       -4.049    &        0.926     \\\\\n",
       "\\textbf{x9}    &       1.7809  &        0.946     &     1.882  &         0.156        &       -1.231    &        4.793     \\\\\n",
       "\\textbf{x10}   &       0.4684  &        1.508     &     0.311  &         0.776        &       -4.331    &        5.268     \\\\\n",
       "\\textbf{x11}   &      -1.9343  &        1.589     &    -1.217  &         0.311        &       -6.991    &        3.123     \\\\\n",
       "\\textbf{x12}   &       0.2972  &        1.251     &     0.238  &         0.828        &       -3.684    &        4.279     \\\\\n",
       "\\textbf{x13}   &      -0.2901  &        1.314     &    -0.221  &         0.839        &       -4.473    &        3.892     \\\\\n",
       "\\textbf{x14}   &      -0.0371  &        1.087     &    -0.034  &         0.975        &       -3.496    &        3.422     \\\\\n",
       "\\textbf{x15}   &       0.6935  &        0.912     &     0.760  &         0.502        &       -2.210    &        3.596     \\\\\n",
       "\\textbf{x16}   &      -0.0302  &        0.799     &    -0.038  &         0.972        &       -2.571    &        2.511     \\\\\n",
       "\\textbf{x17}   &       0.2974  &        1.259     &     0.236  &         0.829        &       -3.710    &        4.305     \\\\\n",
       "\\textbf{x18}   &      -0.7588  &        1.257     &    -0.604  &         0.589        &       -4.759    &        3.242     \\\\\n",
       "\\textbf{x19}   &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{x20}   &       0.2633  &        1.397     &     0.189  &         0.862        &       -4.181    &        4.708     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  6.980 & \\textbf{  Durbin-Watson:     } &    2.414  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.030 & \\textbf{  Jarque-Bera (JB):  } &    5.808  \\\\\n",
       "\\textbf{Skew:}          & -0.482 & \\textbf{  Prob(JB):          } &   0.0548  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.531 & \\textbf{  Cond. No.          } & 9.75e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The input rank is higher than the number of observations. \\newline\n",
       " [3] The smallest eigenvalue is 1.61e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   qsec   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.683\n",
       "Method:                 Least Squares   F-statistic:                     3.583\n",
       "Date:                Thu, 18 Sep 2025   Prob (F-statistic):              0.160\n",
       "Time:                        08:10:31   Log-Likelihood:                -11.403\n",
       "No. Observations:                  19   AIC:                             54.81\n",
       "Df Residuals:                       3   BIC:                             69.92\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         17.8511      0.255     70.116      0.000      17.041      18.661\n",
       "x1         -3.193e-16   1.15e-14     -0.028      0.980   -3.69e-14    3.62e-14\n",
       "x2            -0.6298      2.125     -0.296      0.786      -7.394       6.134\n",
       "x3             1.1599      7.107      0.163      0.881     -21.456      23.776\n",
       "x4            -0.5011      2.350     -0.213      0.845      -7.980       6.978\n",
       "x5             1.4781      2.077      0.712      0.528      -5.133       8.089\n",
       "x6             0.2834      2.720      0.104      0.924      -8.373       8.940\n",
       "x7            -1.2929      1.411     -0.916      0.427      -5.785       3.199\n",
       "x8            -1.5616      0.782     -1.998      0.140      -4.049       0.926\n",
       "x9             1.7809      0.946      1.882      0.156      -1.231       4.793\n",
       "x10            0.4684      1.508      0.311      0.776      -4.331       5.268\n",
       "x11           -1.9343      1.589     -1.217      0.311      -6.991       3.123\n",
       "x12            0.2972      1.251      0.238      0.828      -3.684       4.279\n",
       "x13           -0.2901      1.314     -0.221      0.839      -4.473       3.892\n",
       "x14           -0.0371      1.087     -0.034      0.975      -3.496       3.422\n",
       "x15            0.6935      0.912      0.760      0.502      -2.210       3.596\n",
       "x16           -0.0302      0.799     -0.038      0.972      -2.571       2.511\n",
       "x17            0.2974      1.259      0.236      0.829      -3.710       4.305\n",
       "x18           -0.7588      1.257     -0.604      0.589      -4.759       3.242\n",
       "x19                 0          0        nan        nan           0           0\n",
       "x20            0.2633      1.397      0.189      0.862      -4.181       4.708\n",
       "==============================================================================\n",
       "Omnibus:                        6.980   Durbin-Watson:                   2.414\n",
       "Prob(Omnibus):                  0.030   Jarque-Bera (JB):                5.808\n",
       "Skew:                          -0.482   Prob(JB):                       0.0548\n",
       "Kurtosis:                       5.531   Cond. No.                     9.75e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The input rank is higher than the number of observations.\n",
       "[3] The smallest eigenvalue is 1.61e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos la regresión lineal\n",
    "x_train_e22= sm.add_constant(x_train_scaled22)\n",
    "resultado= sm.OLS(y_train22,x_train_e22).fit()\n",
    "resultado.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee53a3-ec19-45f8-8998-e0581c121cb4",
   "metadata": {},
   "source": [
    "Al escalar y entrenar nuestro modelo, vemos que nuestro r2 incremento a 0.947, además ahora presentamos más variables con relación negativa con nuestra y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0c2f693-dd4b-4e0a-ac7f-1f7b75d2c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de train:  0.9471283557499286\n",
      "R2 de test:  -1.5356274676070791\n"
     ]
    }
   ],
   "source": [
    "#Sacamos lor R2 de x_train y x_test\n",
    "\n",
    "#preparamos x_test\n",
    "x_test_e22=sm.add_constant(x_test_scaled22,  has_constant='add')\n",
    "y_pred22=resultado.predict(x_test_e22)\n",
    "#calculamos r2 de xtrain\n",
    "r2_train22=resultado.rsquared\n",
    "print(\"R2 de train: \",r2_train22)\n",
    "\n",
    "#calculamos r2 de xtest\n",
    "r2_test22=r2_score(y_test22, y_pred22)\n",
    "print(\"R2 de test: \",r2_test22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04894e24-d194-49c4-a8dd-5130c1a8cb06",
   "metadata": {},
   "source": [
    "Sacando las r2 de train y test, podemos ver que hay overfitting, por lo que, el modelo no es tan bueno como se había presentado en la regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253583b-4453-4dfc-bed7-7906aaa4c916",
   "metadata": {},
   "source": [
    "## 3.1 Compara los R2 de los ejercicios 1.1 & 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd38b9f4-c7c2-475b-a25d-9076f5cd9b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 del ejercicio 1.1 sin dummies:  0.8788249154881685\n",
      "R2 del ejercicio 2.1 con dummies:  0.9860599593190703\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 del ejercicio 1.1 sin dummies: \",r2_train)\n",
    "print(\"R2 del ejercicio 2.1 con dummies: \",r2_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08f0a1-0f97-43d3-a474-92eea92c6046",
   "metadata": {},
   "source": [
    "Observando estar r2, diriamos que es mejor el modelo con dummies, pero este queda descartado cuando observamos su r2_test, el cual salio negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f12db5-3cb5-4252-9e6a-b2d5cabe7217",
   "metadata": {},
   "source": [
    "## 3.2 Compara los R2 de los ejercicios 1.2 & 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "727d2053-2b39-463d-9b02-aa0749bc2d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 del ejercicio 1.2 sin dummies:  0.8669774049790414\n",
      "R2 del ejercicio 2.2 con dummies:  0.9471283557499286\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 del ejercicio 1.2 sin dummies: \",r2_train12)\n",
    "print(\"R2 del ejercicio 2.2 con dummies: \",r2_train22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c7bb7-15d2-4fb1-8070-8eedec884af4",
   "metadata": {},
   "source": [
    "Así como la comparación anterior, pasa en esta, pues vemos que el r2 de las dummies es mayor y que explica más el modelo, pero cuando observamos el r2 de test, vemos que hay overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594d12c-679b-4f7b-8af3-1d11aa7215ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
